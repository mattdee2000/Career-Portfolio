{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndrMiwbziPzR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and test data\n",
        "with open('training.json') as f:\n",
        "    training_data = json.load(f)\n",
        "\n",
        "with open('test.json') as f:\n",
        "    test_data = json.load(f)"
      ],
      "metadata": {
        "id": "iTOyRBkRidRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels\n",
        "def extract_features_and_labels(data):\n",
        "    X = [[item['sepal_length'], item['sepal_width'], item['petal_length'], item['petal_width']] for item in data]\n",
        "    y = [item['species'] for item in data]\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train_raw, y_train_raw = extract_features_and_labels(training_data)\n",
        "X_test_raw, y_test_raw = extract_features_and_labels(test_data)"
      ],
      "metadata": {
        "id": "JNyRjhahj5j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess features and labels\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train_raw)\n",
        "y_test = lb.transform(y_test_raw)"
      ],
      "metadata": {
        "id": "ePKzPB4Sj8gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Model - Using the same structure as the original code with backpropagation\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
        "        np.random.seed(1)  # For reproducibility\n",
        "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
        "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.bias_hidden = np.random.rand(1, hidden_size)\n",
        "        self.bias_output = np.random.rand(1, output_size)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward pass\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.final_output = self.sigmoid(self.final_input)\n",
        "        return self.final_output\n",
        "\n",
        "    def backward(self, X, y, output):\n",
        "        # Backpropagation\n",
        "        error = y - output\n",
        "        d_output = error * self.sigmoid_derivative(output)\n",
        "\n",
        "        error_hidden = d_output.dot(self.weights_hidden_output.T)\n",
        "        d_hidden = error_hidden * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += self.hidden_output.T.dot(d_output) * self.learning_rate\n",
        "        self.weights_input_hidden += X.T.dot(d_hidden) * self.learning_rate\n",
        "        self.bias_output += np.sum(d_output, axis=0, keepdims=True) * self.learning_rate\n",
        "        self.bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            self.backward(X, y, output)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward(X)\n"
      ],
      "metadata": {
        "id": "z7OkwjgZj_A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the MLP\n",
        "mlp = MLP(input_size=4, hidden_size=5, output_size=3)\n",
        "\n",
        "# Train the MLP\n",
        "mlp.train(X_train, y_train, epochs=10000)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = mlp.predict(X_test)\n",
        "\n",
        "# Convert predictions back to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "actual_labels = np.argmax(y_test, axis=1)\n",
        "class_labels = lb.classes_\n",
        "\n",
        "# Print predictions and actual labels\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"Prediction: {class_labels[predicted_labels[i]]}, Actual: {class_labels[actual_labels[i]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rOsyJnfkEli",
        "outputId": "98f737c0-3225-4dc6-bab8-442fb52f00bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: setosa, Actual: setosa\n",
            "Prediction: virginica, Actual: virginica\n",
            "Prediction: versicolor, Actual: versicolor\n"
          ]
        }
      ]
    }
  ]
}